{
    "Toxic Language Detection": [
        "task286_olid_offense_judgment",
        "task1607_ethos_text_classification",
        "task333_hateeval_classification_hate_en",
        "task904_hate_speech_offensive_classification",
        "task108_contextualabusedetection_classification",
        "task1721_civil_comments_obscenity_classification",
        "task905_hate_speech_offensive_classification",
        "task327_jigsaw_classification_toxic",
        "task1722_civil_comments_threat_classification",
        "task323_jigsaw_classification_sexually_explicit",
        "task337_hateeval_classification_individual_en",
        "task1725_civil_comments_severtoxicity_classification",
        "task1606_ethos_text_classification",
        "task137_detoxifying-lms_classification_toxicity",
        "task1504_hatexplain_answer_generation",
        "task335_hateeval_classification_aggresive_en",
        "task324_jigsaw_classification_disagree",
        "task609_sbic_potentially_offense_binary_classification",
        "task322_jigsaw_classification_threat",
        "task022_cosmosqa_passage_inappropriate_binary",
        "task1605_ethos_text_classification",
        "task608_sbic_sexual_offense_binary_classification",
        "task326_jigsaw_classification_obscene",
        "task1503_hatexplain_classification",
        "task328_jigsaw_classification_insult",
        "task1604_ethos_text_classification",
        "task607_sbic_intentional_offense_binary_classification",
        "task1502_hatexplain_classification",
        "task1724_civil_comments_insult_classification",
        "task1723_civil_comments_sexuallyexplicit_classification",
        "task325_jigsaw_classification_identity_attack",
        "task1720_civil_comments_toxicity_classification"
    ],
    "Text Completion": [
        "task156_codah_classification_adversarial",
        "task296_storycloze_correct_end_classification",
        "task1389_hellaswag_completion",
        "task455_swag_context_generation",
        "task216_rocstories_correct_answer_generation",
        "task138_detoxifying-lms_classification_fluency",
        "task214_rocstories_incorrect_ending_classification",
        "task964_librispeech_asr_text_auto_completion",
        "task299_storycloze_sentence_generation",
        "task139_detoxifying-lms_classification_topicality",
        "task140_detoxifying-lms_classification_style",
        "task221_rocstories_two_choice_classification",
        "task215_rocstories_incorrect_answer_generation",
        "task213_rocstories_correct_ending_classification",
        "task297_storycloze_incorrect_end_classification",
        "task963_librispeech_asr_next_word_prediction",
        "task453_swag_answer_generation",
        "task105_story_cloze-rocstories_sentence_generation",
        "task268_casehold_legal_answer_generation",
        "task222_rocstories_two_chioce_slotting_classification"
    ],
    "Question Answering": [
        "task309_race_answer_generation",
        "task151_tomqa_find_location_easy_clean",
        "task715_mmmlu_answer_generation_international_law",
        "task692_mmmlu_answer_generation_computer_security",
        "task700_mmmlu_answer_generation_high_school_chemistry",
        "task469_mrqa_answer_generation",
        "task228_arc_answer_generation_easy",
        "task332_tellmewhy_answer_generation",
        "task694_mmmlu_answer_generation_econometrics",
        "task1726_mathqa_correct_answer_generation",
        "task234_iirc_passage_line_answer_generation",
        "task1327_qa_zre_answer_generation_from_question",
        "task1656_gooaq_answer_generation",
        "task698_mmmlu_answer_generation_global_facts",
        "task119_semeval_2019_task10_geometric_mathematical_answer_generation",
        "task669_ambigqa_answer_generation",
        "task054_multirc_write_correct_answer",
        "task706_mmmlu_answer_generation_high_school_mathematics",
        "task754_svamp_common-division_question_answering",
        "task310_race_classification",
        "task703_mmmlu_answer_generation_high_school_geography",
        "task690_mmmlu_answer_generation_college_medicine",
        "task028_drop_answer_generation",
        "task339_record_answer_generation",
        "task1625_disfl_qa_asnwer_generation",
        "task752_svamp_multiplication_question_answering",
        "task697_mmmlu_answer_generation_formal_logic",
        "task083_babi_t1_single_supporting_fact_answer_generation",
        "task865_mawps_addsub_question_answering",
        "task730_mmmlu_answer_generation_professional_medicine",
        "task164_mcscript_question_answering_text",
        "task731_mmmlu_answer_generation_professional_psychology",
        "task239_tweetqa_answer_generation",
        "task049_multirc_questions_needed_to_answer",
        "task1438_doqa_cooking_answer_generation",
        "task024_cosmosqa_answer_generation",
        "task1378_quarel_correct_answer_generation",
        "task084_babi_t1_single_supporting_fact_identify_relevant_fact",
        "task711_mmmlu_answer_generation_high_school_us_history",
        "task230_iirc_passage_classification",
        "task051_multirc_correct_answer_single_sentence",
        "task1601_webquestions_answer_generation",
        "task665_mmmlu_answer_generation_anatomy",
        "task687_mmmlu_answer_generation_college_chemistry",
        "task080_piqa_answer_generation",
        "task490_mwsc_options_generation",
        "task1419_mathqa_gain",
        "task753_svamp_addition_question_answering",
        "task858_inquisitive_span_detection",
        "task709_mmmlu_answer_generation_high_school_psychology",
        "task699_mmmlu_answer_generation_high_school_biology",
        "task597_cuad_answer_generation",
        "task1731_quartz_question_answering",
        "task1565_triviaqa_classification",
        "task696_mmmlu_answer_generation_elementary_mathematics",
        "task1441_doqa_movies_answer_generation",
        "task732_mmmlu_answer_generation_public_relations",
        "task1564_triviaqa_answer_generation",
        "task1581_eqasc-perturbed_answer_generation",
        "task862_asdiv_multidiv_question_answering",
        "task734_mmmlu_answer_generation_sociology",
        "task1424_mathqa_probability",
        "task1421_mathqa_other",
        "task1412_web_questions_question_answering",
        "task1295_adversarial_qa_question_answering",
        "task722_mmmlu_answer_generation_random_topic",
        "task750_aqua_multiple_choice_answering",
        "task104_semeval_2019_task10_closed_vocabulary_mathematical_answer_generation",
        "task733_mmmlu_answer_generation_security_studies",
        "task864_asdiv_singleop_question_answering",
        "task1520_qa_srl_answer_generation",
        "task707_mmmlu_answer_generation_high_school_microeconomics",
        "task598_cuad_answer_generation",
        "task710_mmmlu_answer_generation_high_school_statistics",
        "task596_mocha_question_generation",
        "task118_semeval_2019_task10_open_vocabulary_mathematical_answer_generation",
        "task1380_quarel_correct_option_generation",
        "task667_mmmlu_answer_generation_business_ethics",
        "task866_mawps_multidiv_question_answering",
        "task718_mmmlu_answer_generation_machine_learning",
        "task591_sciq_answer_generation",
        "task751_svamp_subtraction_question_answering",
        "task390_torque_text_span_selection",
        "task047_miscellaneous_answering_science_questions",
        "task1422_mathqa_physics",
        "task735_mmmlu_answer_generation_us_foreign_policy",
        "task460_qasper_answer_generation",
        "task758_msr_sqa_question_answer_generation",
        "task444_com_qa_question_paraphrases_answer_generation",
        "task1661_super_glue_classification",
        "task863_asdiv_multiop_question_answering",
        "task491_mwsc_answer_generation",
        "task016_mctaco_answer_generation_frequency",
        "task727_mmmlu_answer_generation_prehistory",
        "task1135_xcsr_en_commonsense_mc_classification",
        "task170_hotpotqa_answer_generation",
        "task729_mmmlu_answer_generation_professional_law",
        "task1423_mathqa_geometry",
        "task742_lhoestq_answer_generation_frequency",
        "task712_mmmlu_answer_generation_high_school_world_history",
        "task582_naturalquestion_answer_generation",
        "task666_mmmlu_answer_generation_astronomy",
        "task1286_openbookqa_question_answering",
        "task1431_head_qa_answer_generation",
        "task013_mctaco_answer_generation_absolute_timepoint",
        "task007_mctaco_answer_generation_transient_stationary",
        "task867_mawps_multiop_question_answering",
        "task717_mmmlu_answer_generation_logical_fallacies",
        "task041_qasc_answer_generation",
        "task716_mmmlu_answer_generation_jurisprudence",
        "task688_mmmlu_answer_generation_college_computer_science",
        "task702_mmmlu_answer_generation_high_school_european_history",
        "task768_qed_text_span_selection",
        "task704_mmmlu_answer_generation_high_school_government_and_politics",
        "task736_mmmlu_answer_generation_virology",
        "task144_subjqa_question_answering",
        "task153_tomqa_find_location_hard_clean",
        "task1678_mathqa_answer_selection",
        "task595_mocha_answer_generation",
        "task154_tomqa_find_location_hard_noise",
        "task380_boolq_yes_no_question",
        "task705_mmmlu_answer_generation_high_school_macroeconomics",
        "task721_mmmlu_answer_generation_medical_genetics",
        "task1297_qasc_question_answering",
        "task580_socialiqa_answer_generation",
        "task835_mathdataset_answer_generation",
        "task693_mmmlu_answer_generation_conceptual_physics",
        "task194_duorc_answer_generation",
        "task1608_xquad_en_answer_generation",
        "task723_mmmlu_answer_generation_moral_disputes",
        "task686_mmmlu_answer_generation_college_biology",
        "task385_socialiqa_incorrect_answer_generation",
        "task740_lhoestq_answer_generation_quantity",
        "task1296_wiki_hop_question_answering",
        "task1382_quarel_write_correct_answer",
        "task010_mctaco_answer_generation_event_ordering",
        "task725_mmmlu_answer_generation_nutrition",
        "task1293_kilt_tasks_hotpotqa_question_answering",
        "task741_lhoestq_answer_generation_place",
        "task724_mmmlu_answer_generation_moral_scenarios",
        "task344_hybridqa_answer_generation",
        "task1420_mathqa_general",
        "task664_mmmlu_answer_generation_abstract_algebra",
        "task061_ropes_answer_generation",
        "task737_mmmlu_answer_generation_world_religions",
        "task075_squad1.1_answer_generation",
        "task1727_wiqa_what_is_the_effect",
        "task1555_scitail_answer_generation",
        "task004_mctaco_answer_generation_event_duration",
        "task691_mmmlu_answer_generation_college_physics",
        "task165_mcscript_question_answering_commonsense",
        "task302_record_classification",
        "task237_iirc_answer_from_subtext_answer_generation",
        "task701_mmmlu_answer_generation_high_school_computer_science",
        "task229_arc_answer_generation_hard",
        "task073_commonsenseqa_answer_generation",
        "task713_mmmlu_answer_generation_human_aging",
        "task820_protoqa_answer_generation",
        "task745_ai2_arithmetic_questions_arithmetic",
        "task225_english_language_answer_generation",
        "task918_coqa_answer_generation",
        "task708_mmmlu_answer_generation_high_school_physics",
        "task152_tomqa_find_location_easy_noise",
        "task689_mmmlu_answer_generation_college_mathematics",
        "task719_mmmlu_answer_generation_management",
        "task231_iirc_link_classification",
        "task726_mmmlu_answer_generation_philosophy",
        "task720_mmmlu_answer_generation_marketing",
        "task238_iirc_answer_from_passage_answer_generation",
        "task247_dream_answer_generation",
        "task178_quartz_question_answering",
        "task695_mmmlu_answer_generation_electrical_engineering",
        "task728_mmmlu_answer_generation_professional_accounting",
        "task685_mmmlu_answer_generation_clinical_knowledge",
        "task714_mmmlu_answer_generation_human_sexuality",
        "task861_asdiv_addsub_question_answering",
        "task868_mawps_singleop_question_answering",
        "task002_quoref_answer_generation",
        "task058_multirc_question_answering",
        "task615_moviesqa_answer_generation",
        "task1399_obqa_answer_generation"
    ],
    "Misc.": [
        "task1322_country_government_type",
        "task1595_event2mind_text_generation_1",
        "task169_strategyqa_sentence_generation",
        "task308_jeopardy_answer_generation_all",
        "task1403_check_validity_date_mmddyyyy",
        "task183_rhyme_generation",
        "task1428_country_surface_area",
        "task1332_check_leap_year",
        "task1426_country_independence_year",
        "task1498_24hour_to_12hour_clock",
        "task1147_country_currency",
        "task1314_country_abbreviation",
        "task1149_item_check_edible",
        "task307_jeopardy_answer_generation_final",
        "task1319_country_by_barcode_prefix",
        "task306_jeopardy_answer_generation_double",
        "task1317_country_calling_code",
        "task1596_event2mind_text_generation_2",
        "task1191_food_veg_nonveg",
        "task1321_country_continent",
        "task1507_boolean_temporal_reasoning",
        "task921_code_x_glue_information_retreival",
        "task1192_food_flavor_profile",
        "task1333_check_validity_date_ddmmyyyy",
        "task383_matres_classification",
        "task1427_country_region_in_world",
        "task922_event2mind_word_generation",
        "task043_essential_terms_answering_incomplete_questions",
        "task1425_country_iso_numeric",
        "task924_event2mind_word_generation",
        "task305_jeopardy_answer_generation_normal",
        "task567_circa_text_generation",
        "task1193_food_course_classification",
        "task1146_country_capital",
        "task1320_country_domain_tld",
        "task1318_country_national_dish"
    ],
    "Fill in The Blank": [
        "task277_stereoset_sentence_generation_stereotype",
        "task1360_numer_sense_multiple_choice_qa_generation",
        "task1339_peixian_equity_evaluation_corpus_text_completion",
        "task1217_atomic_answer_generation",
        "task965_librispeech_asr_missing_word_prediction",
        "task672_nummersense",
        "task1359_numer_sense_answer_generation",
        "task603_wikitext-103_fill_in_the_blank",
        "task572_recipe_nlg_text_generation",
        "task278_stereoset_sentence_generation_antistereotype"
    ],
    "Sentiment Analysis": [
        "task398_semeval_2018_task1_tweet_joy_detection",
        "task196_sentiment140_answer_generation",
        "task586_amazonfood_polarity_classification",
        "task588_amazonfood_rating_classification",
        "task493_review_polarity_classification",
        "task1532_daily_dialog_emotion_classification",
        "task423_persent_document_sentiment_verification",
        "task1343_amazon_us_reviews_rating",
        "task512_twitter_emotion_classification",
        "task1361_movierationales_classification",
        "task363_sst2_polarity_classification",
        "task929_products_reviews_classification",
        "task746_yelp_restaurant_review_classification",
        "task475_yelp_polarity_classification",
        "task1312_amazonreview_polarity_classification",
        "task819_pec_sentiment_classification",
        "task1313_amazonreview_polarity_classification",
        "task761_app_review_classification",
        "task1310_amazonreview_rating_classification",
        "task399_semeval_2018_task1_tweet_sadness_detection",
        "task518_emo_different_dialogue_emotions",
        "task284_imdb_classification",
        "task587_amazonfood_polarity_correction_classification",
        "task397_semeval_2018_task1_tweet_anger_detection",
        "task293_storycommonsense_emotion_text_generation",
        "task833_poem_sentiment_classification",
        "task1311_amazonreview_rating_classification",
        "task477_cls_english_dvd_classification",
        "task1535_daily_dialog_uniqueness_classification",
        "task478_cls_english_music_classification",
        "task420_persent_document_sentiment_classification",
        "task1338_peixian_equity_evaluation_corpus_sentiment_classifier",
        "task931_dailydialog_classification",
        "task823_peixian-rtgender_sentiment_analysis",
        "task285_imdb_answer_generation",
        "task903_deceptive_opinion_spam_classification",
        "task195_sentiment140_classification",
        "task1292_yelp_review_full_text_categorization",
        "task422_persent_sentence_sentiment_verification",
        "task421_persent_sentence_sentiment_classification",
        "task494_review_polarity_answer_generation",
        "task476_cls_english_books_classification",
        "task517_emo_classify_emotion_of_dialogue",
        "task1536_daily_dialog_happiness_classification",
        "task923_event2mind_classifier",
        "task889_goemotions_classification",
        "task902_deceptive_opinion_spam_classification"
    ],
    "Word Analogy": [
        "task1152_bard_analogical_reasoning_causation",
        "task1153_bard_analogical_reasoning_affordance",
        "task1159_bard_analogical_reasoning_containers",
        "task1155_bard_analogical_reasoning_trash_or_treasure",
        "task1158_bard_analogical_reasoning_manipulating_items",
        "task1157_bard_analogical_reasoning_rooms_for_containers",
        "task1154_bard_analogical_reasoning_travel",
        "task1156_bard_analogical_reasoning_tools"
    ],
    "Dialogue State Tracking": [
        "task1384_deal_or_no_dialog_classification",
        "task1500_dstc3_classification",
        "task766_craigslist_bargains_classification",
        "task1501_dstc3_answer_generation"
    ],
    "Program Execution": [
        "task078_all_elements_except_last_i",
        "task098_conala_list_intersection",
        "task1405_find_median",
        "task125_conala_pair_differences",
        "task1542_every_ith_element_from_starting",
        "task1188_count_max_freq_char",
        "task509_collate_of_all_alphabetical_and_numerical_elements_in_list_separately",
        "task063_first_i_elements",
        "task605_find_the_longest_common_subsequence_in_two_lists",
        "task1087_two_number_sum",
        "task243_count_elements_in_set_intersection",
        "task606_sum_of_all_numbers_in_list_between_positions_i_and_j",
        "task488_extract_all_alphabetical_elements_from_list_in_order",
        "task113_count_frequency_of_letter",
        "task370_synthetic_remove_divisible_by_3",
        "task1150_delete_max_min",
        "task372_synthetic_palindrome_numbers",
        "task367_synthetic_remove_floats",
        "task064_all_elements_except_first_i",
        "task097_conala_remove_duplicates",
        "task158_count_frequency_of_words",
        "task1331_reverse_array",
        "task1446_farthest_integers",
        "task1444_round_power_of_two",
        "task1148_maximum_ascii_value",
        "task756_find_longert_substring_and_return_all_unique_alphabets_in_it",
        "task366_synthetic_return_primes",
        "task365_synthetic_remove_vowels",
        "task163_count_words_ending_with_letter",
        "task1151_swap_max_min",
        "task369_synthetic_remove_odds",
        "task622_replace_alphabets_in_a_list_by_their_position_in_english_alphabet",
        "task499_extract_and_add_all_numbers_from_list",
        "task1445_closest_integers",
        "task094_conala_calculate_mean",
        "task1316_remove_duplicates_string",
        "task124_conala_pair_averages",
        "task095_conala_max_absolute_value",
        "task096_conala_list_index_subtraction",
        "task1443_string_to_number",
        "task079_conala_concat_strings",
        "task1190_add_integer_to_list",
        "task368_synthetic_even_or_odd_calculation",
        "task376_reverse_order_of_words",
        "task160_replace_letter_in_a_sentence",
        "task1189_check_char_in_string",
        "task122_conala_list_index_addition",
        "task505_count_all_numerical_elements_in_list",
        "task1315_find_range_array",
        "task062_bigbench_repeat_copy_logic",
        "task093_conala_normalize_lists",
        "task101_reverse_and_concatenate_all_elements_from_index_i_to_j",
        "task504_count_all_alphabetical_elements_in_list",
        "task208_combinations_of_list",
        "task636_extract_and_sort_unique_alphabets_in_a_list",
        "task162_count_words_starting_with_letter",
        "task245_check_presence_in_set_intersection",
        "task377_remove_words_of_given_length",
        "task755_find_longest_substring_and_replace_its_sorted_lowercase_version_in_both_lists",
        "task099_reverse_elements_between_index_i_and_j",
        "task506_position_of_all_alphabetical_elements_in_list",
        "task523_find_if_numbers_or_alphabets_are_more_in_list",
        "task600_find_the_longest_common_substring_in_two_strings",
        "task100_concatenate_all_elements_from_index_i_to_j",
        "task091_all_elements_from_index_i_to_j",
        "task207_max_element_lists",
        "task507_position_of_all_numerical_elements_in_list",
        "task1551_every_ith_element_from_kth_element",
        "task1088_array_of_products",
        "task378_reverse_words_of_given_length",
        "task206_collatz_conjecture",
        "task205_remove_even_elements",
        "task159_check_frequency_of_words_in_sentence_pair",
        "task123_conala_sort_dictionary",
        "task374_synthetic_pos_or_neg_calculation",
        "task267_concatenate_and_reverse_all_elements_from_index_i_to_j",
        "task1404_date_conversion",
        "task157_count_vowels_and_consonants",
        "task637_extract_and_sort_unique_digits_in_a_list",
        "task1406_kth_smallest_element",
        "task373_synthetic_round_tens_place",
        "task371_synthetic_product_of_list",
        "task244_count_elements_in_set_union",
        "task497_extract_all_numbers_from_list_in_order",
        "task1089_check_monotonic_array",
        "task1194_kth_largest_element",
        "task161_count_words_containing_letter"
    ],
    "Question Generation": [
        "task182_duorc_question_generation",
        "task026_drop_question_generation",
        "task1552_scitail_question_generation",
        "task074_squad1.1_question_generation",
        "task1440_doqa_movies_question_generation",
        "task594_sciq_question_generation",
        "task1602_webquestion_question_genreation",
        "task012_mctaco_question_generation_absolute_timepoint",
        "task246_dream_question_generation",
        "task1580_eqasc-perturbed_question_generation",
        "task443_com_qa_ans_question_generation",
        "task032_winogrande_question_generation_person",
        "task003_mctaco_question_generation_event_duration",
        "task1638_doqa2.1_movies_text_summarization",
        "task599_cuad_question_generation",
        "task184_break_generate_question",
        "task1326_qa_zre_question_generation_from_answer",
        "task1325_qa_zre_question_generation_on_subject_relation",
        "task489_mwsc_question_generation",
        "task859_prost_question_generation",
        "task235_iirc_question_from_subtext_answer_generation",
        "task006_mctaco_question_generation_transient_stationary",
        "task405_narrativeqa_question_generation",
        "task048_multirc_question_generation",
        "task348_squad2.0_unanswerable_question_generation",
        "task1398_obqa_question_generation",
        "task861_prost_mcq_answers_generation",
        "task857_inquisitive_question_generation",
        "task001_quoref_question_generation",
        "task167_strategyqa_question_generation",
        "task060_ropes_question_generation",
        "task568_circa_question_generation",
        "task381_boolq_question_generation",
        "task029_winogrande_full_object",
        "task1609_xquad_en_question_generation",
        "task009_mctaco_question_generation_event_ordering",
        "task1519_qa_srl_question_generation",
        "task1639_doqa2.1_travel_text_summarization",
        "task1637_doqa2.1_cooking_text_summarization",
        "task757_msr_sqa_question_generation",
        "task311_race_question_generation",
        "task236_iirc_question_from_passage_answer_generation",
        "task193_duorc_question_generation",
        "task470_mrqa_question_generation",
        "task461_qasper_question_generation",
        "task739_lhoestq_question_generation",
        "task581_socialiqa_question_generation",
        "task030_winogrande_full_person",
        "task917_coqa_question_generation",
        "task860_prost_mcq_generation",
        "task1657_gooaq_question_generation",
        "task120_zest_text_modification",
        "task821_protoqa_question_generation",
        "task031_winogrande_question_generation_object",
        "task1660_super_glue_question_generation",
        "task389_torque_generate_temporal_question",
        "task1567_propara_question_generation",
        "task1594_yahoo_answers_topics_question_generation",
        "task023_cosmosqa_question_generation",
        "task015_mctaco_question_generation_frequency",
        "task191_hotpotqa_question_generation",
        "task240_tweetqa_question_generation",
        "task649_race_blank_question_generation",
        "task166_clariq_sentence_generation",
        "task1665_trainglecopa_question_generation",
        "task082_babi_t1_single_supporting_fact_question_generation",
        "task1437_doqa_cooking_question_generation",
        "task040_qasc_question_generation",
        "task301_record_question_generation",
        "task519_aquamuse_question_generation"
    ],
    "Text to Code": [
        "task077_splash_explanation_to_sql",
        "task076_splash_correcting_sql_mistake",
        "task130_scan_structured_text_generation_command_action_long",
        "task956_leetcode_420_strong_password_check",
        "task868_cfq_mcd1_explanation_to_sql",
        "task128_scan_structured_text_generation_command_action_short",
        "task211_logic2text_classification",
        "task126_scan_structured_text_generation_command_action_all",
        "task212_logic2text_classification",
        "task210_logic2text_structured_text_generation",
        "task869_cfq_mcd1_sql_to_explanation",
        "task107_splash_question_to_sql"
    ],
    "Question Rewriting": [
        "task442_com_qa_paraphrase_question_generation",
        "task035_winogrande_question_modification_person",
        "task034_winogrande_question_modification_object",
        "task671_ambigqa_text_generation",
        "task1562_zest_text_modification",
        "task1195_disflqa_disfluent_to_fluent_conversion",
        "task670_ambigqa_question_generation",
        "task402_grailqa_paraphrase_generation",
        "task1622_disfl_qa_text_modication",
        "task1345_glue_qqp_question_paraprashing",
        "task121_zest_text_modification"
    ],
    "Summarization": [
        "task522_news_editorial_summary",
        "task1309_amazonreview_summary_classification",
        "task668_extreme_abstract_summarization",
        "task1291_multi_news_summarization",
        "task1355_sent_comp_summarization",
        "task1572_samsum_summary",
        "task1579_gigaword_incorrect_summarization",
        "task672_amazon_and_yelp_summarization_dataset_summarization",
        "task1290_xsum_summarization",
        "task1499_dstc3_summarization",
        "task589_amazonfood_summary_text_generation",
        "task1553_cnn_dailymail_summarization",
        "task1357_xlsum_summary_generation",
        "task1658_billsum_summarization",
        "task618_amazonreview_summary_text_generation",
        "task511_reddit_tifu_long_text_summarization"
    ],
    "Cause Effect Classification": [
        "task393_plausible_result_generation",
        "task392_inverse_causal_relationship",
        "task1393_superglue_copa_text_completion",
        "task828_copa_commonsense_cause_effect",
        "task614_glucose_cause_event_detection",
        "task391_causal_relationship",
        "task827_copa_commonsense_reasoning"
    ],
    "Sentence Composition": [
        "task550_discofuse_sentence_generation",
        "task626_xlwic_sentence_based_on_given_word_sentence_generation",
        "task187_snli_entailment_to_contradiction_text_modification",
        "task628_xlwic_word_with_different_meaning_sentence_generation",
        "task188_snli_neutral_to_entailment_text_modification",
        "task1515_imppres_longtextgeneration",
        "task184_snli_entailment_to_neutral_text_modification",
        "task037_qasc_generate_related_fact",
        "task1368_healthfact_sentence_generation",
        "task203_mnli_sentence_generation",
        "task1364_hans_answer_generation",
        "task189_snli_neutral_to_contradiction_text_modification",
        "task1530_scitail1.1_sentence_generation",
        "task1613_sick_given_category_generate_sentence",
        "task1401_obqa_sentence_generation",
        "task627_xlwic_word_with_same_meaning_sentence_generation",
        "task1556_scitail_passage_generation",
        "task038_qasc_combined_fact",
        "task185_snli_contradiction_to_neutral_text_modification",
        "task186_snli_contradiction_to_entailment_text_modification"
    ],
    "Question Decomposition": [
        "task168_strategyqa_question_decomposition",
        "task176_break_decompose_questions"
    ],
    "Textual Entailment": [
        "task1344_glue_entailment_classification",
        "task190_snli_classification",
        "task1516_imppres_naturallanguageinference",
        "task1388_cb_entailment",
        "task200_mnli_entailment_classification",
        "task1385_anli_r1_entailment",
        "task1387_anli_r3_entailment",
        "task970_sherliic_causal_relationship",
        "task641_esnli_classification",
        "task937_defeasible_nli_social_classification",
        "task202_mnli_contradiction_classification",
        "task935_defeasible_nli_atomic_classification",
        "task936_defeasible_nli_snli_classification",
        "task1386_anli_r2_entailment",
        "task640_esnli_classification",
        "task201_mnli_neutral_classification",
        "task1529_scitail1.1_classification",
        "task199_mnli_classification",
        "task738_perspectrum_classification",
        "task642_esnli_classification",
        "task1554_scitail_classification",
        "task1615_sick_tclassify_b_relation_a",
        "task1612_sick_label_classification"
    ],
    "Word Relation Classification": [
        "task1505_root09_semantic_relation_classification",
        "task1418_bless_semantic_relation_classification",
        "task1429_evalution_semantic_relation_classification",
        "task1583_bless_meronym_classification",
        "task1584_evalution_meronym_classification"
    ],
    "Named Entity Recognition": [
        "task1486_cell_extraction_anem_dataset",
        "task570_recipe_nlg_ner_generation",
        "task1705_ljspeech_classification",
        "task1566_propara_structured_text_generation",
        "task610_conllpp_ner",
        "task1449_disease_entity_extraction_bc5cdr_dataset",
        "task571_recipe_nlg_ner_generation",
        "task1483_chemical_extraction_chemprot_dataset",
        "task1485_organ_extraction_anem_dataset",
        "task1448_disease_entity_extraction_ncbi_dataset",
        "task959_e2e_nlg_text_generation_identify",
        "task1452_location_entity_extraction_btc_corpus",
        "task1447_drug_extraction_ade",
        "task1487_organism_substance_extraction_anem_dataset",
        "task419_persent_answer_generation",
        "task1480_gene_extraction_jnlpba_dataset",
        "task1482_gene_extraction_chemprot_dataset",
        "task1453_person_entity_extraction_btc_corpus",
        "task1479_organization_entity_extraction_btc_corpus",
        "task1481_gene_extraction_bc2gm_dataset",
        "task1484_gene_extraction_linnaeus_dataset"
    ],
    "Text Categorization": [
        "task617_amazonreview_category_text_generation",
        "task1489_sarcasmdetection_tweet_classification",
        "task633_dbpedia_14_answer_generation",
        "task629_dbpedia_14_classification",
        "task198_mnli_domain_classification",
        "task1593_yahoo_answers_topics_classification",
        "task1488_sarcasmdetection_headline_classification",
        "task930_dailydialog_classification",
        "task1630_openpi_classification",
        "task1495_adverse_drug_event_classification",
        "task501_scruples_anecdotes_post_type_verification",
        "task1541_agnews_classification",
        "task1712_poki_classification",
        "task375_classify_type_of_sentence_in_debate",
        "task767_craigslist_bargains_classification",
        "task274_overruling_legal_classification",
        "task1592_yahoo_answers_topics_classfication",
        "task682_online_privacy_policy_text_classification",
        "task197_mnli_domain_answer_generation",
        "task632_dbpedia_14_classification",
        "task521_trivia_question_classification",
        "task495_semeval_headline_classification",
        "task1434_head_qa_classification",
        "task679_hope_edi_english_text_classification",
        "task379_agnews_topic_classification",
        "task744_eurlex_classification",
        "task280_stereoset_classification_stereotype_type",
        "task364_regard_social_impact_classification",
        "task143_odd-man-out_classification_generate_category",
        "task496_semeval_answer_generation",
        "task282_scruples_event_time",
        "task115_help_advice_classification",
        "task681_hope_edi_malayalam_text_classification",
        "task204_mnli_same_genre_classification",
        "task1187_politifact_classification",
        "task1308_amazonreview_category_classification"
    ],
    "Stereotype Detection": [
        "task318_stereoset_classification_gender",
        "task319_stereoset_classification_profession",
        "task279_stereoset_classification_stereotype",
        "task320_stereoset_classification_race",
        "task321_stereoset_classification_religion",
        "task317_crows-pairs_classification_stereotype_type",
        "task316_crows-pairs_classification_stereotype"
    ],
    "Title Generation": [
        "task1356_xlsum_title_generation",
        "task569_recipe_nlg_text_generation",
        "task769_qed_summarization",
        "task288_gigaword_summarization",
        "task1342_amazon_us_reviews_title",
        "task500_scruples_anecdotes_title_generation",
        "task1540_parsed_pdfs_summarization",
        "task619_ohsumed_abstract_title_generation",
        "task219_rocstories_title_answer_generation",
        "task510_reddit_tifu_title_summarization",
        "task1161_coda19_title_generation",
        "task743_eurlex_summarization",
        "task418_persent_title_generation",
        "task220_rocstories_title_classification",
        "task1358_xlsum_title_generation",
        "task1659_title_generation",
        "task1586_scifact_title_generation",
        "task602_wikitext-103_answer_generation"
    ],
    "Information Extraction": [
        "task874_opus_xhosanavy_sr",
        "task578_curiosity_dialogs_answer_generation",
        "task1410_dart_relationship_extraction",
        "task747_glucose_cause_emotion_detection",
        "task1518_limit_answer_generation",
        "task647_answer_generation",
        "task388_torque_token_classification",
        "task958_e2e_nlg_text_generation_parse",
        "task646_answer_generation",
        "task621_ohsumed_yes_no_numerical_answer_generation",
        "task181_outcome_extraction",
        "task1568_propara_classification",
        "task179_participant_extraction",
        "task749_glucose_reverse_cause_emotion_detection",
        "task926_coached_conv_pref_word_generation",
        "task1451_drug_dose_extraction",
        "task1411_dart_subject_identification",
        "task1506_celebrity_minimal_dob_span",
        "task292_storycommonsense_character_text_generation",
        "task748_glucose_reverse_cause_event_detection",
        "task683_online_privacy_policy_text_purpose_answer_generation",
        "task676_ollie_relationship_answer_generation",
        "task1413_dart_object_identification",
        "task678_ollie_actual_relationship_answer_generation",
        "task1517_limit_classfication",
        "task180_intervention_extraction",
        "task1597_nyc_slot_filling",
        "task684_online_privacy_policy_text_information_type_generation",
        "task456_matres_intention_classification",
        "task1510_evalution_relation_extraction"
    ],
    "Speaker Identification": [
        "task906_dialogre_identify_names",
        "task856_conv_ai_2_classification",
        "task909_dialogre_prevalent_speakers",
        "task577_curiosity_dialogs_classification",
        "task1599_smcalflow_classification",
        "task638_multi_woz_classification",
        "task925_coached_conv_pref_classifier",
        "task575_air_dialogue_classification"
    ],
    "Answer Verification": [
        "task241_tweetqa_classification",
        "task056_multirc_classify_correct_answer",
        "task057_multirc_classify_incorrect_answer",
        "task1392_superglue_multirc_answer_verification",
        "task579_socialiqa_classification",
        "task1294_wiki_qa_answer_verification"
    ],
    "Wrong Candidate Generation": [
        "task287_casehold_legal_incorrect_answer_generation",
        "task631_dbpedia_14_incorrect_answer_generation",
        "task283_dream_incorrect_answer_generation",
        "task008_mctaco_wrong_answer_generation_transient_stationary",
        "task492_mwsc_incorrect_answer_generation",
        "task025_cosmosqa_incorrect_answer_generation",
        "task014_mctaco_wrong_answer_generation_absolute_timepoint",
        "task081_piqa_wrong_answer_generation",
        "task011_mctaco_wrong_answer_generation_event_ordering",
        "task454_swag_incorrect_answer_generation",
        "task759_msr_sqa_incorrect_answer_generation",
        "task967_ruletaker_incorrect_fact_generation_based_on_given_paragraph",
        "task1383_quarel_write_incorrect_answer",
        "task1379_quarel_incorrect_answer_generation",
        "task135_winowhy_wrong_reason_generation",
        "task919_coqa_incorrect_answer_generation",
        "task592_sciq_incorrect_answer_generation",
        "task055_multirc_write_incorrect_answer",
        "task303_record_incorrect_answer_generation",
        "task017_mctaco_wrong_answer_generation_frequency",
        "task042_qasc_incorrect_option_generation",
        "task1381_quarel_incorrect_option_generation",
        "task1400_obqa_incorrect_answer_generation",
        "task1558_jfleg_incorrect_answer_generation",
        "task331_gap_incorrect_answer_generation",
        "task005_mctaco_wrong_answer_generation_event_duration"
    ],
    "Explanation": [
        "task223_quartz_explanation_generation",
        "task134_winowhy_reason_generation",
        "task295_semeval_2020_task4_commonsense_reasoning",
        "task192_hotpotqa_sentence_generation",
        "task593_sciq_explanation_generation",
        "task1369_healthfact_sentence_generation"
    ],
    "Grammar Error Correction": [
        "task1415_youtube_caption_corrections_grammar_correction",
        "task1557_jfleg_answer_generation"
    ],
    "Commonsense Classification": [
        "task1200_atomic_classification_xeffect",
        "task1216_atomic_classification_causes",
        "task1196_atomic_classification_oeffect",
        "task1212_atomic_classification_hasproperty",
        "task1207_atomic_classification_atlocation",
        "task1206_atomic_classification_isbefore",
        "task1197_atomic_classification_oreact",
        "task1198_atomic_classification_owant",
        "task1208_atomic_classification_xreason",
        "task136_winowhy_knowledge_categorization",
        "task1211_atomic_classification_hassubevent",
        "task1213_atomic_classification_desires",
        "task1210_atomic_classification_madeupof",
        "task1205_atomic_classification_isafter",
        "task1202_atomic_classification_xneed",
        "task1201_atomic_classification_xintent",
        "task1199_atomic_classification_xattr",
        "task1214_atomic_classification_xwant",
        "task1215_atomic_classification_capableof",
        "task1203_atomic_classification_xreact",
        "task1204_atomic_classification_hinderedby",
        "task1209_atomic_classification_objectuse",
        "task291_semeval_2020_task4_commonsense_validation",
        "task116_com2sense_commonsense_reasoning"
    ],
    "Ethics Classification": [
        "task508_scruples_dilemmas_more_ethical_isidentifiable",
        "task224_scruples_anecdotes_ethical_judgment",
        "task503_scruples_anecdotes_isanswerable",
        "task498_scruples_anecdotes_whoiswrong_classification",
        "task502_scruples_anecdotes_whoiswrong_verification",
        "task106_scruples_ethical_judgment"
    ],
    "Text Matching": [
        "task1285_kpa_keypoint_matching",
        "task148_afs_argument_quality_gay_marriage",
        "task1408_dart_similarity_classification",
        "task149_afs_argument_quality_death_penalty",
        "task276_enhanced_wsc_classification",
        "task147_afs_argument_similarity_gay_marriage",
        "task630_dbpedia_14_classification",
        "task1288_glue_mrpc_paraphrasing",
        "task1354_sent_comp_classification",
        "task1645_medical_question_pair_dataset_text_classification",
        "task289_gigaword_summarization",
        "task624_ohsumed_question_answering",
        "task400_paws_paraphrase_classification",
        "task150_afs_argument_quality_gun_control",
        "task1587_scifact_classification",
        "task566_circa_classification",
        "task1287_glue_qqp_paraphrasing",
        "task146_afs_argument_similarity_gun_control",
        "task1162_coda19_title_classification",
        "task404_grailqa_paraphrase_validation",
        "task145_afs_argument_similarity_death_penalty",
        "task514_argument_consequence_classification",
        "task590_amazonfood_summary_correction_classification",
        "task1347_glue_sts-b_similarity_classification"
    ],
    "Word Semantics": [
        "task142_odd-man-out_classification_no_category",
        "task141_odd-man-out_classification_category",
        "task1508_wordnet_antonyms",
        "task1582_bless_hypernym_generation",
        "task1585_root09_hypernym_generation",
        "task1509_evalution_antonyms",
        "task458_matres_negation_classification",
        "task457_matres_conditional_classification",
        "task625_xlwic_true_or_false_answer_generation",
        "task459_matres_static_classification"
    ],
    "Question Understanding": [
        "task384_socialiqa_question_classification",
        "task248_dream_classification",
        "task462_qasper_classification",
        "task1289_trec_classification",
        "task018_mctaco_temporal_reasoning_presence",
        "task834_mathdataset_classification",
        "task1328_qa_zre_relation_generation_from_question",
        "task044_essential_terms_identifying_essential_words",
        "task019_mctaco_temporal_reasoning_category",
        "task673_google_wellformed_query_classification",
        "task227_clariq_classification",
        "task027_drop_answer_type_generation",
        "task046_miscellaneous_question_typing"
    ],
    "Story Composition": [
        "task269_csrg_counterfactual_story_generation",
        "task270_csrg_counterfactual_context_generation",
        "task067_abductivenli_answer_generation",
        "task059_ropes_story_generation",
        "task071_abductivenli_answer_generation",
        "task068_abductivenli_incorrect_answer_generation",
        "task103_facts2story_long_text_generation",
        "task072_abductivenli_answer_generation"
    ],
    "Pos Tagging": [
        "task345_hybridqa_answer_generation",
        "task1167_penn_treebank_coarse_pos_tagging",
        "task346_hybridqa_classification",
        "task347_hybridqa_incorrect_answer_generation",
        "task382_hybridqa_answer_generation",
        "task584_udeps_eng_fine_pos_tagging",
        "task1168_brown_coarse_pos_tagging",
        "task583_udeps_eng_coarse_pos_tagging",
        "task155_count_nouns_verbs"
    ],
    "Stance Detection": [
        "task209_stancedetection_classification",
        "task513_argument_stance_classification"
    ],
    "Text Quality Evaluation": [
        "task052_multirc_identify_bad_question",
        "task1284_hrngo_informativeness_classification",
        "task674_google_wellformed_query_sentence_generation",
        "task1623_disfl_qa_disfluent_question_classification",
        "task1186_nne_hrngo_classification",
        "task053_multirc_correct_bad_question",
        "task1283_hrngo_quality_classification",
        "task616_cola_classification",
        "task021_mctaco_grammatical_logical",
        "task1589_scifact_classification",
        "task1341_msr_text_classification",
        "task675_google_wellformed_query_sentence_generation"
    ],
    "Section Classification": [
        "task1164_coda19_section_correction_classification",
        "task1163_coda19_section_classification",
        "task352_coda-19_classification"
    ],
    "Fact Verification": [
        "task1366_healthfact_classification",
        "task966_ruletaker_fact_checking_based_on_given_context",
        "task403_creak_commonsense_inference"
    ],
    "Dialogue Act Recognition": [
        "task362_spolin_yesand_prompt_response_sub_classification",
        "task1531_daily_dialog_type_classification",
        "task1394_meta_woz_task_classification",
        "task1534_daily_dialog_question_classification",
        "task1533_daily_dialog_formal_classification"
    ],
    "Gender Classification": [
        "task340_winomt_classification_gender_pro",
        "task343_winomt_classification_profession_anti",
        "task1336_peixian_equity_evaluation_corpus_gender_classifier",
        "task350_winomt_classification_gender_identifiability_pro",
        "task341_winomt_classification_gender_anti",
        "task351_winomt_classification_gender_identifiability_anti",
        "task342_winomt_classification_profession_pro"
    ],
    "Dialogue Generation": [
        "task1714_convai3_sentence_generation",
        "task1590_diplomacy_text_generation",
        "task639_multi_woz_user_utterance_generation",
        "task611_mutual_multi_turn_dialogue",
        "task1600_smcalflow_sentence_generation",
        "task361_spolin_yesand_prompt_response_classification",
        "task1730_personachat_choose_next",
        "task1729_personachat_generate_next",
        "task574_air_dialogue_sentence_generation",
        "task1603_smcalflow_sentence_generation",
        "task360_spolin_yesand_response_generation",
        "task565_circa_answer_generation",
        "task576_curiosity_dialogs_answer_generation"
    ],
    "Sentence Expansion": [
        "task955_wiki_auto_style_transfer"
    ],
    "Intent Identification": [
        "task573_air_dialogue_classification",
        "task1713_convai3_sentence_generation",
        "task932_dailydialog_classification",
        "task294_storycommonsense_motiv_text_generation"
    ],
    "Text Simplification": [
        "task112_asset_simple_sentence_identification",
        "task933_wiki_auto_style_transfer",
        "task934_turk_simplification",
        "task111_asset_sentence_simplification"
    ],
    "Negotiation Strategy Detection": [
        "task359_casino_classification_negotiation_vouch_fair",
        "task356_casino_classification_negotiation_self_need",
        "task354_casino_classification_negotiation_no_need",
        "task353_casino_classification_negotiation_elicit_pref",
        "task358_casino_classification_negotiation_uv_part",
        "task357_casino_classification_negotiation_small_talk",
        "task355_casino_classification_negotiation_other_need"
    ],
    "Mathematics": [
        "task085_unnatural_addsub_arithmetic",
        "task090_equation_learner_algebra",
        "task087_new_operator_addsub_arithmetic",
        "task092_check_prime_classification"
    ],
    "Coreference Resolution": [
        "task249_enhanced_wsc_pronoun_disambiguation",
        "task1391_winogrande_easy_answer_generation",
        "task033_winogrande_answer_generation",
        "task133_winowhy_reason_plausibility_detection",
        "task329_gap_classification",
        "task648_answer_generation",
        "task330_gap_answer_generation",
        "task1390_wscfixed_coreference",
        "task401_numeric_fused_head_reference",
        "task1664_winobias_text_generation",
        "task304_numeric_fused_head_resolution"
    ],
    "Grammar Error Detection": [
        "task1416_youtube_caption_corrections_incorrect_grammar_classification",
        "task089_swap_words_verification",
        "task1346_glue_cola_grammatical_correctness_classification"
    ],
    "Number Conversion": [
        "task1703_ljspeech_textmodification",
        "task1704_ljspeech_textmodification"
    ],
    "Punctuation Error Detection": [
        "task1706_ljspeech_classification"
    ],
    "Paraphrasing": [
        "task177_para-nmt_paraphrasing",
        "task770_pawsx_english_text_modification",
        "task045_miscellaneous_sentence_paraphrasing",
        "task132_dais_text_modification",
        "task1614_sick_text_modify"
    ],
    "Answerability Classification": [
        "task1640_aqa1.0_answerable_unanswerable_question_classification",
        "task233_iirc_link_exists_classification",
        "task1439_doqa_cooking_isanswerable",
        "task020_mctaco_span_based_question",
        "task232_iirc_link_number_classification",
        "task1624_disfl_qa_question_yesno_classification",
        "task349_squad2.0_answerable_unanswerable_question_classification",
        "task520_aquamuse_answer_given_in_passage",
        "task290_tellmewhy_question_answerability",
        "task1442_doqa_movies_isanswerable",
        "task226_english_language_answer_relevance_classification",
        "task050_multirc_answerability",
        "task242_tweetqa_classification"
    ],
    "Data to Text": [
        "task1407_dart_question_generation",
        "task1409_dart_text_generation",
        "task102_commongen_sentence_generation",
        "task957_e2e_nlg_text_generation_generate",
        "task760_msr_sqa_long_text_generation",
        "task1728_web_nlg_data_to_text",
        "task677_ollie_sentence_answer_generation",
        "task1598_nyc_long_text_generation",
        "task1631_openpi_answer_generation"
    ],
    "Discourse Connective Identification": [
        "task563_discofuse_answer_generation"
    ],
    "Linguistic Probing": [
        "task1559_blimp_binary_classification",
        "task114_is_the_given_word_longest",
        "task431_senteval_object_count",
        "task1560_blimp_binary_classification",
        "task428_senteval_inversion",
        "task429_senteval_tense",
        "task430_senteval_subject_count",
        "task515_senteval_odd_word_out",
        "task516_senteval_conjoints_inversion"
    ],
    "Sentence Ordering": [
        "task1548_wiqa_binary_classification",
        "task300_storycloze_order_generation",
        "task217_rocstories_ordering_answer_generation",
        "task218_rocstories_swap_order_answer_generation",
        "task1549_wiqa_answer_generation_missing_step"
    ],
    "Discourse Relation Classification": [
        "task564_discofuse_classification"
    ],
    "Code to Text": [
        "task131_scan_long_text_generation_action_command_long",
        "task110_logic2text_sentence_generation",
        "task127_scan_long_text_generation_action_command_all",
        "task129_scan_long_text_generation_action_command_short"
    ],
    "Sentence Perturbation": [
        "task275_enhanced_wsc_paraphrase_generation",
        "task1670_md_gender_bias_text_modification",
        "task413_mickey_en_sentence_perturbation_generation",
        "task1669_md_gender_bias_text_modification"
    ],
    "Entity Relation Classification": [
        "task472_haspart_classification"
    ],
    "Overlap Extraction": [
        "task039_qasc_find_overlapping_words",
        "task281_points_of_correspondence"
    ],
    "Translation": [
        "task547_alt_translation_entk_en",
        "task560_alt_translation_en_entk"
    ],
    "Style Transfer": [
        "task928_yelp_positive_to_negative_style_transfer",
        "task927_yelp_negative_to_positive_style_transfer"
    ],
    "Irony Detection": [
        "task386_semeval_2018_task3_irony_detection",
        "task387_semeval_2018_task3_irony_classification"
    ],
    "Spelling Error Detection": [
        "task088_identify_typo_verification"
    ],
    "Entity Generation": [
        "task471_haspart_answer_generation"
    ],
    "Speaker Relation Classification": [
        "task907_dialogre_identify_relationships",
        "task908_dialogre_identify_familial_relationships"
    ],
    "Keyword Tagging": [
        "task620_ohsumed_medical_subject_headings_answer_generation",
        "task645_summarization",
        "task613_politifact_text_generation",
        "task036_qasc_topic_word_to_generate_related_fact",
        "task623_ohsumed_yes_no_answer_generation"
    ],
    "Coherence Classification": [
        "task066_timetravel_binary_consistency_classification",
        "task1573_samsum_classification",
        "task065_timetravel_consistent_sentence_classification",
        "task070_abductivenli_incorrect_classification",
        "task298_storycloze_correct_end_classification",
        "task069_abductivenli_classification"
    ],
    "Preposition Prediction": [
        "task585_preposition_classification"
    ],
    "Spam Classification": [
        "task109_smsspamcollection_spamsmsdetection"
    ],
    "Poem Generation": [
        "task1711_poki_text_generation"
    ],
    "Sentence Compression": [
        "task1340_msr_text_compression_compression"
    ]
}